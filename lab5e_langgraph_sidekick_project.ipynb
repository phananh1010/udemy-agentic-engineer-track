{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e03f63b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated, List, Dict, Any, Optional\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langchain.tools import tool\n",
    "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
    "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "import requests\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde8d42-36be-4110-8a2b-d049209f24f7",
   "metadata": {},
   "source": [
    "# evaluattor output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fd9d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use evaluator node, which should output this\n",
    "class EvaluatorOutput(BaseModel):\n",
    "    feedback: str = Field(description=\"Feedback on the assistant's response\")\n",
    "    success_criteria_met: bool = Field(description=\"whether the success criteria have been met\")\n",
    "    user_input_needed: bool= Field(description=\"whether more input or clarification is needed from user, or the assistant is stuck\")\n",
    "\n",
    "\n",
    "# main graph state\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[List[Any], add_messages]\n",
    "    success_criteria: str\n",
    "    feedback_on_work: Optional[str] #why duplicated with evaluatorOuput?\n",
    "    success_criteria_met: bool\n",
    "    user_input_needed: bool\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ba180e-8d21-4456-a3eb-0d3aaef781ef",
   "metadata": {},
   "source": [
    "# declare browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "220e2c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "async_browser = create_async_playwright_browser(headless=False)\n",
    "toolkit = PlayWrightBrowserToolkit.from_browser(async_browser=async_browser)\n",
    "tools = toolkit.get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc249e93-3b98-451b-8175-d0e874f692f4",
   "metadata": {},
   "source": [
    "# declare LLM for nodes in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e14724c5-6bc4-4360-8c0e-e04832ed3219",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_openai = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "llm_deepseek = ChatOpenAI(\n",
    "    model=\"deepseek-chat\",                # DeepSeek chat model name\n",
    "    base_url=\"https://api.deepseek.com/v1\",\n",
    "    api_key=os.environ[\"DEEPSEEK_API_KEY\"],\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "llm = llm_deepseek\n",
    "\n",
    "worker_llm = llm\n",
    "worker_llm_with_tools = worker_llm.bind_tools(tools)\n",
    "\n",
    "evaluator_llm = llm\n",
    "evaluator_llm_with_output = evaluator_llm.with_structured_output(EvaluatorOutput) #hijacking toolcalling or function calling method to regulate output format: https://forum.langchain.com/t/clarification-on-how-pydantic-schema-descriptions-are-used-in-with-structured-output/1612?utm_source=chatgpt.com \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45089a40-bf16-40e8-9166-7557276fd983",
   "metadata": {},
   "source": [
    "# declare worker node in langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94770128-b1ac-4e9d-94ce-b1e1a37a155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker(state: State) -> Dict[str, Any]:\n",
    "    \"\"\"processing logic of the worker node\"\"\"\n",
    "    system_message = f\"\"\"You are a helpful assistant that use tools to complete tasks.\n",
    "Keep working on task until you have questions or clarification from users or success criteria are met.\n",
    "Success criteria:\n",
    "{state[\"success_criteria\"]}\n",
    "Reply either with a question or with your final response.\n",
    "If question, clearly state the question. Example: please clarify for <the unclear thing> is either <option 1> or <option 2> or <option 3> etc...\n",
    "If finished, final response should not be a question.\n",
    "\"\"\"\n",
    "\n",
    "    if state.get(\"feedback_on_work\"):\n",
    "        system_message = f\"\"\"\n",
    "Your previous reply is incomplete and rejected. Here is the feedback: \n",
    "{state['feedback_on_work']}\n",
    "Use this feedback to continue the assignment, verify if success criteria is met or question to users is required.\n",
    "\"\"\"\n",
    "    found_system_message = False\n",
    "    messages = state[\"messages\"]\n",
    "    for message in messages:\n",
    "        if isinstance(message, SystemMessage):\n",
    "            found_system_message = True\n",
    "    # we only append system message once, should be at the first time this worker is invoked\n",
    "    if not found_system_message: \n",
    "        messages = [SystemMessage(content=system_message)] + messages\n",
    "    #why processing task receive raw HumanMesage and AIMessage class\n",
    "    response = worker_llm_with_tools.invoke(messages) # -> No worries, langchain automatically extract {\"role\": ..., \"content\": ...} as input to LLM. https://docs.langchain.com/oss/python/langchain/models\n",
    "    #response here should have tool_calls key if they decide to invoke\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def worker_router(state:State):\n",
    "    \"\"\"custom made tool routing function for conditional edge in langgraph\"\"\"\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if hasattr(last_message, \"tool_calls\") and last_message.tool_calls: #note: last_message maybe HumanMessage or AIMessage, not a dict\n",
    "        return \"tools\"\n",
    "    else:\n",
    "        return \"evaluator\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d12ef-80bf-49f0-8b3f-bb51b744cd1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea4491e-0e64-4ce6-b472-d7d9c9e1012e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2abd9e32-958a-4f0f-a6f5-e41af5aa67e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(messages: List[Any]) -> str:\n",
    "    conversation = \"Conversation history: \\n\\n\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            conversation += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            text = message.content or \"[Tools use]\"\n",
    "            conversation += f\"Assistant: {text}\\n\"\n",
    "    return conversation  #but here we only get content\n",
    "\n",
    "def evaluator(state: State) -> State:\n",
    "    last_response = state[\"messages\"][-1].content\n",
    "\n",
    "    system_message = \"\"\"You are strict and succint evaluator who determines if a task is completed successfully by an Assistant or not.\n",
    "Assess the Assistant's last response, and provide feedback and decision whether the success criteria has been met.\n",
    "\"\"\"\n",
    "    user_message = f\"\"\"You are evaluating a conversation between the User and Assistant.\n",
    "Conversation history with assistant, starting with user original request is:\n",
    "{format_conversation(state[\"messages\"])}\n",
    "\n",
    "Success criteria for this assignment:\n",
    "{state[\"success_criteria\"]}\n",
    "\n",
    "Final response from the Assistant for evaluation:\n",
    "{last_response}\n",
    "\n",
    "Now, begin evaluating.\n",
    "\"\"\"\n",
    "    if state[\"feedback_on_work\"]: \n",
    "        user_message += f\"Also, in previous attempt from the Assistant, you provided feedback: {state['feedback_on_work']}\\n\"\n",
    "        user_message += f\"If assistant repeat the mistakes, consider responding that user input is required.\\n\"\n",
    "\n",
    "    evaluator_message = [SystemMessage(content=system_message), HumanMessage(content=user_message)]\n",
    "\n",
    "    eval_result = evaluator_llm_with_output.invoke(evaluator_message)\n",
    "    new_state = { \n",
    "        #message include information that also attached to the state\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Evaluator's feedback on this answer: {eval_result.feedback}\"}],\n",
    "        \"feedback_on_work\": eval_result.feedback,\n",
    "        \"success_criteria_met\": eval_result.success_criteria_met,\n",
    "        \"user_input_needed\": eval_result.user_input_needed\n",
    "    }\n",
    "    return new_state\n",
    "\n",
    "def evaluator_router(state: State):\n",
    "    \"\"\"Evaluator router, used on conditional edge on langgraph, Nope, maybe it as there is no tool call, but may be still condition to worker node\"\"\"\n",
    "    if state['success_criteria_met'] or state['user_input_needed']:\n",
    "        return \"END\" # ok criteria, ready to answer, or need to double check\n",
    "    else:\n",
    "        return \"worker\"\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51acc40f-d183-4a33-8863-922d9785916d",
   "metadata": {},
   "source": [
    "### Now define the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b91dd5-54e3-4b82-9386-9b265ca1296f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"worker\", worker)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "graph_builder.add_node(\"evaluator\", evaluator)\n",
    "\n",
    "graph_builder.add_edge(START, \"worker\")\n",
    "graph_builder.add_conditional_edges(\"worker\", worker_router, {'tools': 'tools', 'evaluator': 'evaluator'})\n",
    "graph_builder.add_edge(\"tools\", \"worker\")\n",
    "graph_builder.add_conditional_edges(\"evaluator\", evaluator_router, {\"END\": END, 'worker': 'worker'})\n",
    "\n",
    "memory_ram = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory_ram)\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdd2b160-025c-4a23-9a73-0bfddbf6e081",
   "metadata": {},
   "source": [
    "### Gradio call back and super step??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15f1a85-263f-4c3e-b7f6-188e163ed305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_thread_id() -> str:\n",
    "    return str(uuid.uuid4())\n",
    "\n",
    "async def process_message(message, success_criteria, history, thread):\n",
    "    config = {\"configurable\": {\"thread_id\": thread}}\n",
    "\n",
    "    state = {\n",
    "        \"messages\": message,\n",
    "        \"success_criteria\": success_criteria,\n",
    "        \"feedback_on_work\": None,\n",
    "        \"success_criteria_met\": False,\n",
    "        \"user_input_needed\": False\n",
    "    }\n",
    "    result = await graph.ainvoke(state, config=config)\n",
    "\n",
    "    user = {\"role\": \"user\", \"content\": message} # a user message input to LLM\n",
    "    reply = {\"role\": \"assistant\", \"content\": result[\"messages\"][-2].content}\n",
    "    feedback = {\"role\": \"assistant\", \"content\": result[\"messages\"][-1].content}\n",
    "\n",
    "    return history + [user, reply, feedback]\n",
    "\n",
    "async def reset():\n",
    "    return \"\", \"\", None, make_thread_id()\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c67fbd5-2a8b-40f6-b5ff-b1a2b36aa8db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/gradio/queueing.py\", line 763, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/gradio/route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/gradio/blocks.py\", line 2106, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/gradio/blocks.py\", line 1586, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/gradio/utils.py\", line 1015, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_37109/1081320194.py\", line 14, in process_message\n",
      "    result = await graph.ainvoke(state, config=config)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/pregel/main.py\", line 3158, in ainvoke\n",
      "    async for chunk in self.astream(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/pregel/main.py\", line 2971, in astream\n",
      "    async for _ in runner.atick(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/pregel/_runner.py\", line 304, in atick\n",
      "    await arun_with_retry(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/pregel/_retry.py\", line 137, in arun_with_retry\n",
      "    return await task.proc.ainvoke(task.input, config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 705, in ainvoke\n",
      "    input = await asyncio.create_task(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/futures.py\", line 289, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
      "    future.result()\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/futures.py\", line 202, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/tasks.py\", line 316, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langgraph/_internal/_runnable.py\", line 473, in ainvoke\n",
      "    ret = await self.afunc(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/runnables/config.py\", line 608, in run_in_executor\n",
      "    return await asyncio.get_running_loop().run_in_executor(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/futures.py\", line 289, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/tasks.py\", line 385, in __wakeup\n",
      "    future.result()\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/asyncio/futures.py\", line 202, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"/home/anh/miniforge3/lib/python3.12/concurrent/futures/thread.py\", line 59, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/runnables/config.py\", line 599, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_37109/1012339474.py\", line 35, in evaluator\n",
      "    eval_result = evaluator_llm_with_output.invoke(evaluator_message)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 3141, in invoke\n",
      "    input_ = context.run(step.invoke, input_, config, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/runnables/base.py\", line 5548, in invoke\n",
      "    return self.bound.invoke(\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 398, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1117, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 927, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_core/language_models/chat_models.py\", line 1221, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1356, in _generate\n",
      "    raise e\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1330, in _generate\n",
      "    _handle_openai_bad_request(e)\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/langchain_openai/chat_models/base.py\", line 1324, in _generate\n",
      "    self.root_client.chat.completions.with_raw_response.parse(\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/openai/_legacy_response.py\", line 364, in wrapped\n",
      "    return cast(LegacyAPIResponse[R], func(*args, **kwargs))\n",
      "                                      ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/openai/resources/chat/completions/completions.py\", line 184, in parse\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/openai/_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/anh/workspace/course-udemy-agentic-enginer/.venv./lib/python3.12/site-packages/openai/_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': 'This response_format type is unavailable now', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n",
      "During task with name 'evaluator' and id '4040b038-44de-b647-f843-dc56247d1353'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## Sidekick Personal Co-worker\")\n",
    "    thread = gr.State(make_thread_id())\n",
    "    with gr.Row():\n",
    "        chatbot = gr.Chatbot(\n",
    "            label=\"Sidekick\",\n",
    "            height=300,\n",
    "        )\n",
    "\n",
    "    with gr.Group():\n",
    "        with gr.Row():\n",
    "            message = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"Your request to your sidekick\",\n",
    "            )\n",
    "\n",
    "        with gr.Row():\n",
    "            success_criteria = gr.Textbox(\n",
    "                show_label=False,\n",
    "                placeholder=\"What are your success criteria?\",\n",
    "            )\n",
    "\n",
    "    with gr.Row():\n",
    "        reset_button = gr.Button(\"Reset\", variant=\"stop\")\n",
    "        go_button = gr.Button(\"Go!\", variant=\"primary\")\n",
    "\n",
    "    message.submit(\n",
    "        process_message,\n",
    "        [message, success_criteria, chatbot, thread],\n",
    "        [chatbot],\n",
    "    )\n",
    "\n",
    "    success_criteria.submit(\n",
    "        process_message,\n",
    "        [message, success_criteria, chatbot, thread],\n",
    "        [chatbot],\n",
    "    )\n",
    "\n",
    "    go_button.click(\n",
    "        process_message,\n",
    "        [message, success_criteria, chatbot, thread],\n",
    "        [chatbot],\n",
    "    )\n",
    "\n",
    "    reset_button.click(\n",
    "        reset,\n",
    "        [],\n",
    "        [message, success_criteria, chatbot, thread]\n",
    "    )\n",
    "\n",
    "demo.launch()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9882ec-23f1-453c-8464-ed4481e2b78d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d9d70-f040-405c-89dc-c8c96831da9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
